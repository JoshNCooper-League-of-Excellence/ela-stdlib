//module elexify;

/*
  This is a generalized lexing library suitable for most use cases.

  The design is modeled after ela's own lexer, so it's probably a bit
  more well suited for programming languages.

  However it's absolutely suitable for other formats, such as JSON, XAML, etc.
*/

/*
  USAGE:

  Explained:
    (1) the keywords map is for alphanumeric (which in this lexer can always start with, or contain underscores)
      identifiers that get associated with a specific u32.

    (2) the operators map is for punctuation that gets associated with a specific u32. to understand what gets recognized
      as punctuation, look into the C standard library's 'ispunct', we use that function here. (Linux manpages, available online too, are a good resource).

    (3) the reserved words list is very similar to the keywords map, except it doesn't associate each item with a u32.
      instead, it will prepend a customizable character to the front of the string, and return it as an identifier.
      This is especially useful when making something like a DSL that transpiles to C, where things like 'void' or any
      reserved word in C would clash normally. this avoids that clashing, and your frontend doesn't have to worry about it.

    (4) the 'state' object is used to control a stack of various inputs, or to switch between different inputs.
      this is primarily used for things like text "include"s, where you encounter an "include" to a file,
      start to read it, and want to jump back to your last "state" when done.

      This can be achieved by simply pushing a state on the lexer, and continuing to execute.
      Once the lexer gets to an EOF token (and it has more states left on its stack)
      it will pop the finished state, and resume it's operation wherever you left off on your old state.

      I'm sure this could also be used to parallelize your parsing, however care must be taken as the containers used
      for keywords, operators, and reserved words are not thread safe, nor is the lookahead buffer used within each state.
      This may not be important for your use case, but it's worth noting.

    (5) We simply push the first state onto the lexers stack, before beginning lexing.
      It should be obvious, but we take a shallow copy of the state when we pass this by value.
      You can keep track of your states and copy them back if you wanted to do something like multi threading,
      but as of now, it's meant to contain it's own mutable state, and not be read back from.

    (6) Here, we have a loop that continually 'eat's or consumes tokens from the stream, until it reaches the EOF.
      We also have a bunch of helpers in the lexer, such as 'peek', 'lookahead', 'expect', etc. These, of course,
      are for your parser to use while reading from the stream.

  fn main() {
    mut lexer := Lexer::new(
      (1) (a Map!<str, u32> of keywords),
      (2) (a Map!<str, u32> of operators),
      (3) (a List!<str>     of reserved words),
    );

    (4) mut state := State::from_file("input_file.json");
    (5) lexer.push_state(state);

    (6) while {
      token := lexer.eat();
      if token.kind == TOKEN_EOF then break;

      // Do something with your token :D
    }
  }
*/

/*
  --------------------------------------------------------------------------
  ## A FULL, CORRECT EXAMPLE ###############################################
  --------------------------------------------------------------------------
    import fmt;
    import lexer::*;

    type None :: Option!<s32>::None;

    // We don't need to worry about clashes with
    // the builtin token types, because the lexer
    // uses incredibly large u32's to represent those,
    // with the express intent to avoid said clashes.

    // You may want to type these types in your own enum,
    // as shown below.
    enum u32 {
      Add,
      OpenParen,
      CloseParen,
      OpenAngle,
      CloseAngle,
      OpenCurly,
      CloseCurly,
      Semicolon,
      Comma,
      DoubleColon,
      Arrow,
      Dot,
      Assign,
      Fn,

      // type the constants of the lexer.
      Eof         = lexer::TOKEN_EOF,
      Identifier  = lexer::TOKEN_IDENTIFIER,
      Integer     = lexer::TOKEN_INTEGER,
      Float       = lexer::TOKEN_FLOAT,
      String      = lexer::TOKEN_STRING,
      Char        = lexer::TOKEN_CHAR,
    }

    fn operators() -> Map!<str, lexer::u32> {
      return Map!<str, lexer::u32>::init(.[
        ("+",  u32::Add),
        ("(",  u32::OpenParen),
        (")",  u32::CloseParen),
        (";",  u32::Semicolon),
        ("<",  u32::OpenAngle),
        (">",  u32::CloseAngle),
        (",",  u32::Comma),
        ("=",  u32::Assign),
        ("::", u32::DoubleColon),
        ("->", u32::Arrow),
        ("{",  u32::OpenCurly),
        ("}",  u32::CloseCurly),
        (".",  u32::Dot),
      ]);
    }

    fn keywords() -> Map!<str, lexer::u32> {
      return Map!<str, lexer::u32>::init(.[
        ("fn", Fn u32),
      ]);
    }

    fn reserved() -> List!<str> {
      return List!<str>::init(.["volatile"]);
    }

    fn main() {
      mut lexer := Lexer::new(
        Some(operators()),
        Some(keywords()),
        Some(reserved()),
      );

      mut state := State::from_file("sample.txt");

      lexer.push_state(state);

      while {
        token := lexer.eat();

        if token.is_eof() then break;

        // print the tokens out.
        println(token.to_string());
      }
    }

  -----------------------------------------------------------------------
  ## END ################################################################
  -----------------------------------------------------------------------
*/

/*
  TODO:
    add customizable string delimiters,
    char delimiters,
    and comment syntax.
*/

import interned::*;
type InternedString :: Interned!<String>;

import math::{
  clamp,
  max,
};

import map::*;
import fmt::*;
import fs::*;
import stringstream::*;

const TOKEN_EOF        : u32 = -1;
const TOKEN_IDENTIFIER : u32 = -2;
const TOKEN_INTEGER    : u32 = -3;
const TOKEN_FLOAT      : u32 = -4;
const TOKEN_STRING     : u32 = -5;
const TOKEN_CHAR       : u32 = -6;

import io;


struct Span {
  line: s64,
  column: s64,
  file: s64,
}

impl Span {
  fn files() -> *mut List!<String> {
    static mut files: List!<String>;
    return &mut files;
  }

  fn to_string(self) -> String {
    mut files := Span::files();
    filename := (*files)[self.file];
    return format("%:%:%", (filename, self.line, self.column), FormatOptions::default());
  }
}

fn location_to_source_view!<T>(msg: T, span: Span) -> String where T: AsSlice!<u8> {
  using mut builder: StringStream;

  mut formatter: Formatter = .{
    writer: &mut builder,
  };

  builder.append("\n\033[1;31mat:\n\t\033[1;34m");
  span.format(&mut formatter);
  builder.append("\033[0m\n");
  builder.appendf("\033[1;3;31merror: %", (msg,), FormatOptions::default());
  builder.append("\033[0m\n");

  filename := (*Span::files())[span.file];
  mut file_data := File::read_all(filename).unwrap();
  defer file_data.destroy();

  line := span.line as s32;
  mut clamped_begin := clamp(line - 3, line - 3, line) as s32;
  mut clamped_end := clamp(line + 3, line, line + 3) as s32;

  clamped_begin = max(0, clamped_begin);
  clamped_end = max(0, clamped_end);

  mut lines : [String] =
    file_data
      .split('\n')
      .subslice(clamped_begin..clamped_end);

  builder.append("\033[1;3;37m\n");
  for i in 0..lines.length {
    line : str = .{
      data: lines[i].data as *mut u8,
      length: lines[i].length,
    };

    builder.appendf("%\n", (line,), FormatOptions::default());

    if i == 2 {
      for i in 1..span.column-1 {
        builder.append(" ");
      }
      for i in 0..3 {
        builder.append("^");
      }
      builder.append("\n");
    }
  }

  return builder.get_string();
}

impl Span {
  fn to_error_string!<StringT>(self, msg: StringT) -> String where StringT: AsSlice!<u8> {
    return location_to_source_view(msg, self);
  }
}

impl Format for Span {
  fn format(*const self, f: *mut fmt::Formatter) {
    f.writer.append_then_free(self.to_string());
  }
}

fn lex_error!<T>(msg: T, span: Span) where T: AsSlice!<u8> {
  mut string := location_to_source_view(msg, span);
  defer string.destroy();
  panic(string.as_str());
}

struct Token {
  // TODO: put this in an option.
  value:    Option!<InternedString>,
  kind:     u32,
  span:     Span,
}

impl Token {
  fn Eof() -> Token {
    static eof: Token = .{
      kind: TOKEN_EOF,
    };
    return eof;
  }

  fn iskind(self, kind: u32) -> bool {
    return self.kind == kind;
  }

  fn is_eof(self) -> bool {
    return self.kind == TOKEN_EOF;
  }

  fn new(span: Span, value: Option!<String>, kind: u32) -> Token {
    if value is Option!<String>::Some(string) {
      return .{
        value: Option!<InternedString>::Some(InternedString::new(string)),
        kind: kind,
        span: span,
      };
    } else {
      return .{
        value: Option!<InternedString>::None,
        kind: kind,
        span: span,
      };
    }

  }
};

impl Format for Token {
  fn format(*const self, f: *mut fmt::Formatter) {
    f.writer.append("Token {\n  span: ");
    f.writer.append_then_free(self.span.to_string());

    mut value: Option!<String>;
    if self.value is Option!<InternedString>::Some(string) {
      value = Option!<String>::Some(*string.data);
    } else {
      value = Option!<String>::None;
    }
    f.writer.appendf("\n  kind: %,\n  value: %\n}", (self.kind, value), f.options.quoted());
  }
}

impl Token {
  fn to_string(self) -> String {
    mut builder: StringStream;
    mut formatter: Formatter = .{
      writer: &mut builder,
      options: FormatOptions::default()
    };
    defer {
      builder.destroy();
    }

    self.format(&mut formatter);
    return builder.get_string();
  }
}

struct State {
  input: String,
  path: String,
  pos: s64,
  col: s64,
  line: s64,
  file_idx: s64,
}

impl State {
  fn new(path: String, input: String, file_idx: s64) -> Self {
    return .{
      path: path,
      input: input,
      file_idx: file_idx,
      pos: 0,
      col: 1,
      line: 1,
    };
  }

  fn from_file!<Path>(filename: Path) -> Self where Path: AsSlice!<u8> {
      canonical: String = if canonical_path(filename) is Option!<String>::Some(v) {
        return v;
      } else {
        io::panicf("[elexify]: file '%' was unable to be canonicalized.", (filename,));
        return .{};
      }

      parent: String = if parent_path(canonical) is Option!<String>::Some(v) {
        return v;
      } else {
        io::panicf("[elexify]: unable to get the parent directory of canonicalized path: canonical_path=%", (canonical,));
        return .{};
      }

      if !change_directory(parent) {
        io::panicf("[elexify]: unable to change directory to parent of canonicalized path: parent=%, canonical_path=%", (parent, canonical));
      }

      input: String = if File::read_all(canonical) is Result!<String, String>::Ok(v) {
        return v;
      } else {
        io::printlnf("[elexify]: unable to read file from (relative path): %, (canonicalized): %, (parent dir): %", (filename, canonical, parent));
        return .{};
      }

      mut found := false;
      mut file_idx := 0;
      for file in *Span::files() {
        if file == canonical {
          found = true;
          break;
        }
        file_idx++;
      }
      if (!found) {
        Span::files().push(canonical);
      }
      return State::new(canonical, input, file_idx);
    }
}

struct Lexer {
  operators: Map!<str, u32>,
  keywords:  Map!<str, u32>,
  reserved:  List!<str>,
  states:    List!<State>,
  lookahead_buffer: List!<Token>,
  reserved_placeholder: String,
  whitespace: List!<u8>,
}

impl Lexer {
  fn new(operators: Option!<Map!<str, u32>>, keywords: Option!<Map!<str, u32>>, reserved: Option!<List!<str>>, whitespace: Option!<List!<u8>>) -> Self {
    return .{
      operators:  operators.or_else(.{}),
      keywords:   keywords.or_else(.{}),
      reserved:   reserved.or_else(.{}),
      reserved_placeholder: String::from("$"),
      whitespace: whitespace.or_else(List!<u8>::init(.[' '])),
    };
  }
}

impl Destroy for Lexer {
  fn destroy(*mut self, recursive: bool = true) {
    self.operators.destroy();
    self.keywords.destroy();
    self.reserved.destroy();
    self.states.destroy();
    self.lookahead_buffer.destroy();
    self.reserved_placeholder.destroy();
  }
}

impl Lexer {
  fn has_work(self) -> bool {
    return self.lookahead_buffer[0].kind != TOKEN_EOF;
  }

  fn push_state(*mut self, state: State) {
    self.states.push(state);
  }

  fn fill_buffer_if_needed(*mut self) {
    while self.lookahead_buffer.length < 8 {
      if self.states.is_empty() {
        self.lookahead_buffer.push(Token::Eof());
      } else {
        self.get_token(self.states.back_mut().unwrap());
        // We dont manage states here, the parser needs to be able to detect when it's swapped
        if self.peek().kind == TOKEN_EOF {
          // dont fill the buffer with EOF, just one.
          break;
        }
      }
    }
  }

  fn expect(*mut self, kind: u32) -> Token {
    token := self.eat();
    if token.kind != kind {
      lex_error(
        format("unexpected token: '%' ...\nexpected '%' instead.",
          (token.kind, kind), FormatOptions::default()
        ),
        token.span
      );
    }
    return token;
  }

  fn peek(*mut self) -> Token {
    self.fill_buffer_if_needed();
    return self.lookahead_buffer.front().unwrap();
  }

  fn eat(*mut self) -> Token {
    self.fill_buffer_if_needed();
    return self.lookahead_buffer.pop_front();
  }

  fn next(*mut self) -> u32 {
    return self.peek().kind;
  }

  fn get_token(*mut self, state: *mut State) {
    mut token_builder: StringStream;
    defer token_builder.destroy();

    while state.pos < state.input.length {
      token_builder.clear();
      mut c: u8 = state.input[state.pos];

      /* Newline */
      if c == '\n' {
        state.pos++;
        state.line++;
        state.col = 1;
        continue;
      }

      /* Check for whitespace operators first */
      mut whitespace_match: String = .{};
      mut temp_pos := state.pos;
      mut temp_col := state.col;

      /* token-yielding symbols below. */
      mut span : Span = .{
        line: state.line,
        column: state.col,
        file: state.file_idx
      };


      // Try to match whitespace sequences as operators
      while temp_pos < state.input.length {
        mut temp_c := state.input[temp_pos];
        if !self.whitespace.contains(temp_c, fn(a: u8, b: u8) -> bool { return a == b; }) {
          break;
        }
        whitespace_match.push(temp_c);
        option := self.operators.get(whitespace_match.as_str());
        if (option is Option!<u32>::Some) {
          // Found a whitespace operator match
          state.pos = temp_pos + 1;
          state.col = temp_col + 1;
          self.lookahead_buffer.push(Token::new(span, None(), option.unwrap()));
          whitespace_match.destroy();
          return;
        }
        temp_pos++;
        temp_col++;
      }
      whitespace_match.destroy();

      /* Regular Whitespace (single character, not an operator) */
      if self.whitespace.contains(c, fn(a: u8, b: u8) -> bool { return a == b; }) {
        state.pos++;
        state.col++;
        continue;
      }

      /* Line comments */
      if c == '/' && state.pos + 1 < state.input.length && state.input[state.pos + 1] == '/' {
        state.pos += 2;
        state.col += 2;
        while c != '\n' && state.pos < state.input.length {
          state.pos++;
          c = state.input[state.pos];
        }
        if state.pos < state.input.length {
          state.pos++;
          state.col = 1;
          state.line++;
        }
        continue;
      }

      /* Block comments */
      if c == '/' && state.pos + 1 < state.input.length && state.input[state.pos + 1] == '*' {
        state.pos += 2;
        state.col += 2;
        while state.pos + 1 < state.input.length && state.input[state.pos] != '*' || state.input[state.pos + 1] != '/' {
          if state.input[state.pos] == '\n' {
            state.line++;
            state.col = 1;
          } else {
            state.col++;
          }
          state.pos++;
          c = state.input[state.pos];
        }
        if state.pos < state.input.length {
          state.pos += 2;
          state.col += 2;
        }
        continue;
      }


      // Characters.
      if c == '\'' {
        start := state.pos;
        state.pos++;
        state.col++;
        c = state.input[state.pos];
        mut codepoint: u32 = -1;

        // Escape characters.
        if c == '\\' {
          state.pos++;
          state.col++;
          c = state.input[state.pos];
          state.pos++;
          state.col++;
          if c == 'n' {
            codepoint = '\n';
          } else if c == 'v' {
            codepoint = '\v';
          } else if c == 'b' {
            codepoint = '\b';
          } else if c == 't' {
            codepoint = '\t';
          } else if c == 'f' {
            codepoint = '\f';
          } else if c == 'r' {
            codepoint = '\r';
          } else if c == '\'' {
            codepoint = '\'';
          } else if c == '\\' {
            codepoint = '\\';
          } else if c == '\"' {
            codepoint = '\"';
          } else if c == '0' {
            codepoint = '\0';
          } else if c == 'x' || c == 'u' || c == 'U' {
            mut num_digits: u64;
            if c == 'x' {
              num_digits = 2;
            } else if c == 'u' {
              num_digits = 4;
            } else {
              num_digits = 8;
            }
            state.pos++;
            state.col++;
            codepoint = 0;
            for i in 0..num_digits {
              if (state.pos >= state.input.length || !std::c::isxdigit(state.input[state.pos])) {
                lex_error("invalid hexadecimal escape sequence", span);
              }
              buffer: [u8; 2] = .[
                state.input[state.pos],
                '\0',
              ];
              mut hex_value: u8 = state.input[state.pos];
              if hex_value >= '0' && hex_value <= '9' {
                hex_value -= '0';
              } else if hex_value >= 'a' && hex_value <= 'f' {
                hex_value -= 'a' - 10;
              } else if hex_value >= 'A' && hex_value <= 'F' {
                hex_value -= 'A' - 10;
              }
              codepoint = (codepoint << 4) | hex_value;
              state.pos++;
              state.col++;
            }
          } else if c >= '0' && c <= '7' { // Octal escape sequence
            codepoint = 0;
            mut i := 0;
            while i < 3 && c > '0' && c < '7' {
              codepoint = (codepoint << 3) | (c - '0');
              state.pos++;
              state.col++;
              c = state.input[state.pos];
              ++i;
            }
          } else {
            lex_error(format("invalid escape sequence %", (c,), FormatOptions::default()), span);
          }
        } else if (c & 0x80) == 0 {
          codepoint = c;
          state.pos++;
          state.col++;
        } else {
          mut num_bytes := 0;
          if ((c & 0xE0) == 0xC0) {
            num_bytes = 2;
          }
          else if ((c & 0xF0) == 0xE0) {
            num_bytes = 3;
          }
          else if ((c & 0xF8) == 0xF0) {
            num_bytes = 4;
          }
          else {
            lex_error("invalid utf8 char", span);
          }

          for i in 0..num_bytes {
            if (state.pos >= state.input.length || (i > 0 && (state.input[state.pos] & 0xC0) != 0x80)) {
              lex_error("invalid UTF-8 continuation byte", span);
            }
            codepoint = (codepoint << 6) | (state.input[state.pos] & 0x3F);
            state.pos++;
            state.col++;
          }
        }

        c = state.input[state.pos];
        if (c != '\'') {
          lex_error(format("invalid char literal: too many characters %", (codepoint,), FormatOptions::default()), span);
        }
        state.pos++; // move past '
        state.col++;
        mut buffer: [u8; 32];
        std::c::snprintf(buffer, 32 * sizeof(u8), "0x%X"c, codepoint);
        self.lookahead_buffer.push(Token::new(span, Some(String::from_ptr(buffer)), TOKEN_CHAR));
        return;
      }

      // Strings
      if c == '\"' {
        state.pos++;
        state.col++;
        c = state.input[state.pos];
        while (state.pos < state.input.length) {
          c = state.input[state.pos];
          if (c == '\"') {
            break;
          } if (c == '\n') {
            lex_error("You can't directly embed a '\\n' in string by just letting it span multiple lines", span);
          } else if (c == '\\') {
            if (state.pos + 1 < state.input.length) {
              token_builder.append_byte(c);
              state.pos++;
              state.col++;
              token_builder.append_byte(state.input[state.pos]);
              state.pos++;
              state.col++;
            } else {
              lex_error("incomplete escape sequence at end of input", span);
            }
          } else {
            token_builder.append_byte(c);
            state.pos++;
            state.col++;
            c = state.input[state.pos];
          }
        }
        if c != '\"' {
          panic("unescaped string");
        }
        state.pos++;
        state.col++;
        self.lookahead_buffer.push(Token::new(span, Some(token_builder.get_string()), TOKEN_STRING));
        return;
      }

      // Identifiers, Keywords.
      // Check if the character is alphabetic, underscore, or a UTF-8 start byte
      if (c.is_alpha() || c == '_' || (c & 0x80) != 0) {
        while (state.pos < state.input.length) {
          if (c.is_alphanumeric() || c == '_') {
            token_builder.append_byte(c);
            state.pos++;
            state.col++;
            c = state.input[state.pos];
          // Check if the character is a UTF-8 start byte
          } else if ((c & 0x80) != 0) {
            mut num_bytes := 0;
            if (c & 0xE0) == 0xC0 {
              num_bytes = 2;
            } else if (c & 0xF0) == 0xE0 {
              num_bytes = 3;
            } else if (c & 0xF8) == 0xF0 {
              num_bytes = 4;
            } else {
              // Stop processing if it's not a valid UTF-8 start byte
              break;
            }
            for i in 0..num_bytes {
              if (state.pos >= state.input.length || (i > 0 && (state.input[state.pos] & 0xC0) != 0x80)) {
                break; // Stop processing if it's not a valid UTF-8 continuation byte
              }
              token_builder.append_byte(state.input[state.pos]);
              state.pos++;
              state.col++;
            }
            c = state.input[state.pos];
          } else {
            break; // Stop processing if it's not a valid identifier character
          }
        }

        mut value := token_builder.get_string();

        if self.keywords.contains(value.as_str()) {
          self.lookahead_buffer.push(Token::new(span, None(), self.keywords.get(value.as_str()).unwrap()));
          value.destroy();
          return;
        } else if self.reserved.contains(value.as_str(), fn (a: str, b: str) -> bool {
          return a == b;
        }) {
          // we prepend a $ on C's reserved words so we don't have any invisible overlap between the source
          // and target languages
          mut new_value := self.reserved_placeholder.clone();
          new_value.append(value);
          value.destroy();
          value = new_value;
        }
        self.lookahead_buffer.push(Token::new(span, Some(value), TOKEN_IDENTIFIER));
        return;
      }

      // Operators and Punctuation.
      if c.is_ascii_punctuation() {
        mut longest_match: String = .{};
        mut current_match: String = .{};
        while state.pos < state.input.length && c.is_ascii_punctuation() {
          if c == '\"'
            then break;

          current_match.push(state.input[state.pos]);
          option := self.operators.get(current_match.as_str());

          if (option is Option!<u32>::Some) {
            longest_match = current_match;
          } else if !longest_match.is_empty() {
            self.lookahead_buffer.push(Token::new(span, None(), self.operators.get(longest_match.as_str()).unwrap()));
            return;
          }

          state.pos++;
          state.col++;
          c = state.input[state.pos];
        }

        if !longest_match.is_empty() {
          self.lookahead_buffer.push(Token::new(span, None(), self.operators.get(longest_match.as_str()).unwrap()));
          return;
        } else {
          lex_error(format("unable to lex operator :: \'%\'", (current_match,), FormatOptions::default()), span);
        }
      }

      if c.is_digit() {
        mut is_float: bool = false;
        mut is_hex: bool = false;
        mut is_bin: bool = false;
        if c == '0' && (state.input[state.pos + 1] == 'x' || state.input[state.pos + 1] == 'X') {
          is_hex = true;
          state.pos += 2; // Skip '0x'
          state.col += 2;
          c = state.input[state.pos];
        } else if c == '0' && (state.input[state.pos + 1] == 'b' || state.input[state.pos + 1] == 'B') {
          is_bin = true;
          state.pos += 2; // Skip '0b'
          state.col += 2;
          c = state.input[state.pos];
        }

        while state.pos < state.input.length && (c.is_digit() || c == '.' || (is_hex && c.is_hex_digit()) ||
                            (is_bin && (c == '0' || c == '1')) || c == '_') {
          if (c == '_') {
            state.pos++;
            state.col++;
            c = state.input[state.pos];
          }

          if (c == '.' && state.pos + 1 < state.input.length && (state.input[state.pos + 1] == '.' || !state.input[state.pos+1].is_digit())) {
            break;
          }

          if (c == '.') {
            if (is_float) {
              lex_error("got too many '.' periods in a float literal.", span);
            }
            is_float = true;
          }
          token_builder.append_byte(c);
          state.pos++;
          state.col++;
          c = state.input[state.pos];
          if (c == '_') {
            state.pos++;
            state.col++;
            c = state.input[state.pos];
          }
        }

        mut value := token_builder.get_string();

        if (is_hex) {
          mut hex := String::from("0x");
          hex.append_then_free(value);
          self.lookahead_buffer.push(Token::new(span, Some(hex), TOKEN_INTEGER));
        } else if (is_bin) {
          mut bin := String::from("0b");
          bin.append_then_free(value);
          self.lookahead_buffer.push(Token::new(span, Some(bin), TOKEN_INTEGER));
        } else if (!is_float) {
          self.lookahead_buffer.push(Token::new(span, Some(value), TOKEN_INTEGER));
        } else {
          self.lookahead_buffer.push(Token::new(span, Some(value), TOKEN_FLOAT));
        }
        return;
      }

    }

    self.lookahead_buffer.push(Token::Eof());
  }
}
