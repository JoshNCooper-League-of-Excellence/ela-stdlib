import fs::*;
import fmt::*;

TokenType :: enum {
  Invalid,
  True,
  False,
  Null,
  Eof,
  Colon,
  Number,
  String,
  LCurly,
  RCurly,
  LBracket,
  RBracket,
  Comma,
}

Token :: struct {
  type : s32,
  value : String,
  line: s32,
  column: s32,
}

impl Token {
  Invalid :: fn() -> #self {
    v: #self;
    return v;
  }
}

#static json_token_type_names := str.[
  "Invalid",
  "True",
  "False",
  "Null",
  "Eof",
  "Colon",
  "Number",
  "String",
  "LCurly",
  "RCurly",
  "LBracket",
  "RBracket",
  "Comma",
];

JsonLexer :: struct {
  line_start: s32,
  cur_line: s32,
  // filename/source of input.
  file: String,
  // input data.
  input: String,
  // position in input stream.
  position: u32,
  // lookahead buffer
  lookahead_buffer : Token[],
}

impl JsonLexer {
  create :: fn(file: String, input: String) -> #self {
    return .{
      file: file,
      input: input,
    };
  }
  
  get_location_string :: fn(self) -> String {
    column := self.position - self.line_start;
    line := self.cur_line + 1;
    return format("%:%:%", (self.file, line, column), FormatOptions::default());
  }

  get_token :: fn(*mut self) -> Result!<Token, String> {
    alias Result :: Result!<Token, String>;
    mut token : Token;

    token.type = TokenType::Eof;
    token.column = self.position - self.line_start;
    token.line = self.cur_line + 1;

    if self.position >= self.input.length || self.input[self.position] == 0 {
      return Result::Ok(token);
    }


    // TODO: handle UTF8.
    mut c := self.input[self.position];

    // whitespace
    // TODO: this should handle tabs, no? perhaps isspace does that.
    while self.position < self.input.length {
      if c == '\n' || c == '\r' {
        self.line_start = self.position;
        self.cur_line++;
      } else if !isspace(c) {
        break;
      }
      self.position++;
      c = self.input[self.position];
    }

    token.column = self.position - self.line_start;
    token.line = self.cur_line + 1;

    if self.position >= self.input.length || self.input[self.position] == 0 {
      return Result::Ok(token);
    }

    // comments
    if c == '/' {
      self.position++;
      if self.position >= self.input.length {
        mut location := self.get_location_string();
        defer location.deinit();
        return Result::Err(format("at \"%\" unexpected end of input %", (location, c), FormatOptions::default(),))
      }
      c = self.input[self.position];
      if c != '/' {
        location := self.get_location_string();
        return Result::Err(format("at \"%\" expected /, got %", (location, c), FormatOptions::default(),))
      }
      while c != '\n' && c != '\r' {
        self.position++;
        if self.position >= self.input.length || self.input[self.position] == 0 {
          token.type = TokenType::Eof;
          return Result::Ok(token);
        }
        c = self.input[self.position];
      }
      return self.get_token();
    }


    // I had to inline isdigit for some reason.
    // it causes C errors.
    if c >= '0' && c <= '9' /* || isdigit(c) */ {
      // numbers
      len : s32;
      start : s32 = self.position;
      while (c >= '0' && c <= '9' || c == '.') && self.position < self.input.length {
        len++;
        self.position++;
        c = self.input[self.position];
      }

      token.value = .{
        data: strndup(self.input.data + start, len),
        length: len
      };

      token.type = TokenType::Number;
      return Result::Ok(token);
      // operators
    } else if c == ':' {
      token.value = String::from(":");
      token.type = TokenType::Colon;
      self.position++;
      return Result::Ok(token);
    } else if c == '{' {
      token.value = String::from("{");
      token.type = TokenType::LCurly;
      self.position++;
      return Result::Ok(token);
    } else if c == '}' {
      token.value = String::from("}");
      token.type = TokenType::RCurly;
      self.position++;
      return Result::Ok(token);
    } else if c == '[' {
      token.value = String::from("[");
      token.type = TokenType::LBracket;
      self.position++;
      return Result::Ok(token);
    } else if c == ']' {
      token.value = String::from("]");
      token.type = TokenType::RBracket;
      self.position++;
      return Result::Ok(token);
    } else if c == ',' {
      token.value = String::from(",");
      token.type = TokenType::Comma;
      self.position++;
      return Result::Ok(token);
    } else if c == '\"' {
      self.position++;
      c = self.input[self.position];
      len : s32;
      start : s32 = self.position;
      while c != '\"' && self.position < self.input.length {
        if c == '\n' || c == '\r' {
          self.line_start = self.position;
          self.cur_line++;
        }
        len++;
        self.position++;
        c = self.input[self.position];
      }
      self.position++;

      token.value = .{
        data: strndup(self.input.data + start, len),
        length: len
      };

      token.type = TokenType::String;
      return Result::Ok(token);
    } else if self.position + 4 <= self.input.length && strncmp(self.input.data + self.position, "true"c, 4) == 0 {
      token.value = String::from("true"); 
      token.type = TokenType::True;
      self.position += 4;
      return Result::Ok(token);
    } else if self.position + 5 <= self.input.length && strncmp(self.input.data + self.position, "false"c, 5) == 0 {
      token.value = String::from("false");
      token.type = TokenType::False;
      self.position += 5;
      return Result::Ok(token);
    } else if self.position + 4 <= self.input.length && strncmp(self.input.data + self.position, "null"c, 4) == 0 {
      token.value = String::from("null");
      token.type = TokenType::Null;
      self.position += 4;
      return Result::Ok(token);
    } else {
      return Result::Ok(token);
    }
  }
}

impl JsonLexer {

  ensure_buffer_is_full :: fn(*mut self) {
    while self.lookahead_buffer.length < 8 {
      self.lookahead_buffer.push(self.get_token().unwrap());
    }
  }

  eat :: fn(*mut self) -> Token {
    self.ensure_buffer_is_full();
    token := self.lookahead_buffer[0];
    for i in 0..self.lookahead_buffer.length - 1 {
      self.lookahead_buffer.data[i] = self.lookahead_buffer.data[i + 1];
    }
    self.lookahead_buffer.length--;
    return token;
  }

  peek :: fn(*mut self) -> Token {
    self.ensure_buffer_is_full();
    return self.lookahead_buffer[0];
  }

  expect_types :: fn(*mut self, types: InitList!<s32>) -> Result!<Token, String> {
    token := self.eat();

    // this should never happen.
    // we are the consumer of this API, but I guess maybe someone might want to use this?
    if types.length == 0 {
      loc := #location;
      panic(format("json lexers `expect_types` got an empty set of types to expect, at \"%\"", (loc,), FormatOptions::default(),).as_str());
    }

    // We do this without the string building so that we can only do that expensive heavy allocating procedure if we
    // fail. this should be much more performant.
    for i in 0..types.length {
      type := types.data[i];
      if token.type == type {
        return Result!<Token, String>::Ok(token);
      }
    }

    mut builder: StringBuilder;
    defer builder.deinit();

    for i in 0..types.length {
      builder.append_then_free(format("| %", (json_token_type_names.data[types.data[i]],), FormatOptions::default(),));
    }

    types_string := builder.get_string();

    error := format("at: \"%:%:%\" :: unexpected token, expected \"%\", got \"%\"", (
        self.file, token.line, token.column,
        types_string,
        json_token_type_names.data[token.type]
      ),
      FormatOptions::default(),
    );

    return Result!<Token, String>::Err(error);
  }

  expect_type :: fn(*mut self, type: s32) -> Result!<Token, String> {
    // TODO: it's much cheaper if we just check this, instead of making list lol.
    // saves a stack alloc and a function call.
    return self.expect_types(.[type]);
  }
}