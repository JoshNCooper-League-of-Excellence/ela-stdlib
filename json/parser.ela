alias JsonResult :: Result!<*mut JsonValue, String>;

fn parse(lexer: *mut JsonLexer) -> JsonResult {
  mut token_result := lexer.expect_types(.[
    TokenType::LBracket,
    TokenType::LCurly,
    TokenType::Number,
    TokenType::String,
    TokenType::True,
    TokenType::False,
    TokenType::Null,
  ]);

  if token_result.is_err()
    then return token_result.propagate();

  value : *mut JsonValue = new(JsonValue.{
    type: JsonValueType::Invalid,
  });

  mut token := token_result.unwrap();

  switch token.type {
    TokenType::LBracket: {
      value.type = JsonValueType::Array;
      value.array = .{};

      token = lexer.peek();

      if token.type == TokenType::RBracket {
        lexer.eat();
        return JsonResult::Ok(value);
      }

      while token.type != TokenType::RBracket {
        value_result := parse(lexer);
        if value_result.is_err()
          then return value_result.propagate();

        value.array.push(value_result.unwrap());

        token_result = lexer.expect_types(.[
          TokenType::RBracket, 
          TokenType::Comma
        ]);
        if token_result.is_err()
          then return token_result.propagate();
        token = token_result.unwrap();
      }
    }
    TokenType::LCurly: {
      value.type = JsonValueType::Object;
      value.object = .{};

      if lexer.peek().type == TokenType::RCurly {
        lexer.eat();
        return JsonResult::Ok(value);
      }

      while token.type != TokenType::RCurly {
        
        token_result = lexer.expect_type(TokenType::String);
        if token_result.is_err() 
          then return token_result.propagate();
        
        key_token := token_result.unwrap();

        token_result = lexer.expect_type(TokenType::Colon);
        if token_result.is_err() 
          then return token_result.propagate();

        value_result := parse(lexer);
        if value_result.is_err() 
          then return value_result.propagate();
        
        val := value_result.unwrap();

        value.object.insert(key_token.value, val);

        token_result = lexer.expect_types(.[
          TokenType::RCurly, 
          TokenType::Comma
        ]);

        if token_result.is_err() 
          then return token_result.propagate();

        token = token_result.unwrap();
      }
    }
  }
  
  if token.type == TokenType::Number {
    value.type = JsonValueType::Number;
    value.number = atof(token.value.data);
  } else if token.type == TokenType::String {
    value.type = JsonValueType::String;
    value.string = token.value;
  } else if token.type == TokenType::True {
    value.type = JsonValueType::Boolean;
    value.boolean = true;
  } else if token.type == TokenType::False {
    value.type = JsonValueType::Boolean;
    value.boolean = false;
  } else if token.type == TokenType::Null {
    value.type = JsonValueType::Null;
  }

  return JsonResult::Ok(value);
}

fn parse_file(file: str) -> JsonResult {
  result := File::read_all(file);
  if result.is_err() {
    return JsonResult::Err(result.err.to_string(get_default_allocator()))
  }

  mut lexer := JsonLexer::create(file.to_string(get_default_allocator()), result.unwrap());
  return parse(&mut lexer);
}

fn parse_string(s: str) -> JsonResult {
  mut lexer := JsonLexer::create(":<loaded from string>:".to_string(get_default_allocator()), s.to_string(get_default_allocator()));
  return parse(&mut lexer);
}